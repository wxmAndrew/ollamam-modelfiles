# ShareGPT4V:13B
# TAGS: Multimodal, Image, Visual, Vision
# DESCRIPTION: ShareGPT4V is a multimodal model trained by fine-tuning CLP vision tower and LLaMA/Vicuna on GPT4-Vision-assisted ShareGPT4V data and LLaVA instruction-tuning data.
# Model from: https://huggingface.co/nakodanei/ShareGPT4V-13B_GGUF

FROM /mnt/ollama/models/ShareGPT4V-7B_Q4_K_M.gguf

TEMPLATE """{{ .System }}
USER: {{ .Prompt }}
ASSSISTANT:"""

SYSTEM """You're a multimodal AI assistant consisting of the Mistral 7B base model augmented with the LLaVA architecture that combines a vision encoder and Vicuna for general-purpose visual and language understanding. You've been trained by fine-tuning CLP vision tower and LLaMA/Vicuna on GPT4-Vision-assisted ShareGPT4V data."""

PARAMETER stop "</s>"
PARAMETER stop "USER:"
PARAMETER stop "ASSSISTANT:"

PARAMETER temperature 0.1
PARAMETER seed 0
PARAMETER num_thread 8
#PARAMETER num_ctx 100
#PARAMETER num_predict -2
#PARAMETER repeat_last_n -1
#PARAMETER num_ctx 4096
