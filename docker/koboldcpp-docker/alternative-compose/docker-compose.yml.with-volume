version: '3.9'
services:
  koboldcpp:
    container_name: koboldcpp
    restart: always
    volumes:
      - '${MODEL_DIR}:/app/models'
      - kobold:/koboldcpp
    ports:
      - '7860:80'
    image: 'noneabove1182/koboldcpp-gpu:latest'
    ulimits:
      memlock: -1
    mem_limit: 50gb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    command:
      [
        "python3",
        "koboldcpp.py",
        "--model",
        "/app/models/${MODEL}",
        "--port",
        "80",
        "--threads",
        "6",
        "--usemlock",
        "--usecublas",
        "0",
        "--gpulayers",
        "18",
        "--forceversion",
        "405"
      ]
volumes:
  kobold:
