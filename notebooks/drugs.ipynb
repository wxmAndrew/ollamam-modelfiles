{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install base library and stuff to get a 7B model to fit into colab RAM limits"
      ],
      "metadata": {
        "id": "ifzZ59dsZiJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/EGjoni/DRUGS.git\n",
        "!pip install bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "0aaFwmGtM2ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make output text wrap in colab for easier reading"
      ],
      "metadata": {
        "id": "sViqvc2BZtac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6PW_KNCM1xr"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import bitsandbytes #necessary to fit in colab\n",
        "import accelerate #necessary to fit in colab\n",
        "import torch\n",
        "from transformers import AutoTokenizer, TextStreamer, GenerationConfig, AutoModelForCausalLM\n",
        "from drugs.dgenerate import DRUGS\n",
        "\n",
        "model_id = \"NousResearch/Llama-2-7b-chat-hf\" #Feel free to change this to a better model. But only LLama2 variants are supported at the moment.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "sober_model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", load_in_8bit=True)\n",
        "sober_model.eval()\n",
        "streamer = TextStreamer(tokenizer)\n",
        "\n",
        "drugs = DRUGS()\n",
        "model = drugs.inject(sober_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bHsu9dA0M1xz",
        "outputId": "2c162a07-c000-438e-a137-cfc7667a245e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Dosage { run: \"auto\", form-width: \"50%\", display-mode: \"form\" }\n",
        "# @markdown How much noise to inject. Range technically 0 - to infinity. Where pi is way too much (as it can allow for vectors that point in the exact opposite direction). You can go even higher, but shouldn't.\n",
        "dose_theta = 0.101 # @param {type:\"slider\", min:0, max:1, step:0.001}\n",
        "drugs.set_A_dose_theta(dose_theta) #you can also specify K_dose_theta, V_dose_theta, Q_dose_theta, or any combination of the 4.\n",
        "#If you opt for changing the type, make sure you update the type in the dose_shape cel after this one too.\n",
        "\n",
        "\n",
        "#sneaking this in here. Just makes the text wrap in cel outputs so it doesn't yeet offscreen.\n",
        "from IPython.display import display, HTML\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "cellView": "form",
        "id": "C1HsNYm-M1x0",
        "outputId": "06eb49d5-577f-4f54-d490-5c834ac36e2d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title DRµG profile { run: \"auto\" }\n",
        "# @markdown ###**Advanced control. Lets you specify how much various depths of the network are injected with how much noise.**\n",
        "# @markdown ---\n",
        "# @markdown How deep to inject noise. 0 corresponds to first layer, 1 corresponds to last layer.\n",
        "injection_depth = 0.4 # @param {type:\"slider\", min:0, max:1, step:0.001}\n",
        "# @markdown How many adjacent layers the noise should affect. 0 means no adjacent layers, 1 means all of the layers in the model. 0.5 means half the total number of model layers on either side.\n",
        "spread = 0.301 # @param {type:\"slider\", min:0, max:1, step:0.001}\n",
        "\n",
        "drug_profile = ([ #you can add as many of these injection sites as you want\n",
        "    {'depth': (injection_depth-(spread*1.01)), 'peakratio': 0}, #ramp up from 0 noise\n",
        "    {'depth': (injection_depth-spread), 'peakratio': 1}, #sustained peak at max  (dose_theta) noise\n",
        "    {'depth': (injection_depth+spread), 'peakratio' : 1}, #sustained peak at max  (dose_theta) noise\n",
        "    {'depth': (injection_depth+(spread*1.01)), 'peakratio' : 0}], #cooldown to 0 noise\n",
        "'ceil') #other options include 'floor', and 'interpolate'\n",
        "drugs.set_A_dose_shape(drug_profile) #each profile (A, K, Q, or V) can be independently injected into different layers, if you are expecially picky about what your noise is doing to which things.\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **You can edit the code for more finegrained control over which layers get how much noise.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq9SfRAUM1x1"
      },
      "source": [
        "## Chat\n",
        "\n",
        "By default this notebook prompts you for input. If viewed in a browser, a dialogue may pop up asking you to say something (but in colab it should ask for input directly in the cel).\n",
        "\n",
        "Note that all variety in the model's responses is due purely to the noise being injected, the selected token is ALWAYS whatever the model thinks is the most likely one!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PijNNp0xM1x2"
      },
      "outputs": [],
      "source": [
        "#If you don't see an input prompt, stop the cell and run it again. Not sure why it's finicky.\n",
        "\n",
        "initial_input = str(input(\"\\bAsk Something:\"))\n",
        "tokenized_start = tokenizer.apply_chat_template([\n",
        "    {'role': 'system',\n",
        "    'content': 'You are Alan Watts.'},\n",
        "    {'role': 'user',\n",
        "     'content': initial_input}\n",
        "], return_tensors='pt')\n",
        "model.dgenerator.past_key_values = None #temporary hack to clear cache.\n",
        "with torch.no_grad():\n",
        "  while True:\n",
        "    generated_tokens = model.Dgenerate(\n",
        "            input_ids = tokenized_start,\n",
        "            streamer = streamer\n",
        "        )\n",
        "    print(\"\\n\\nAsk Something:\", end=\"\")\n",
        "    model.cold_shower(True) #Sets the kv-cache back to theoretically pure baseline, if this is important to you.\n",
        "    await_input = str(input(\": \"))\n",
        "    tokenized_start = tokenizer.apply_chat_template([{\n",
        "        'role': 'user',\n",
        "        'content': await_input}], return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOTE: If you don't see an input box when running the cel above, stop the cell and run it again.\n",
        "(Not sure why it's finicky)"
      ],
      "metadata": {
        "id": "rM6xVCyosFtx"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}