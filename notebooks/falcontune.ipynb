{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP"
      ],
      "metadata": {
        "id": "35Tg9p0JE63P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rmihaylov/falcontune.git\n",
        "!wget https://huggingface.co/TheBloke/falcon-40b-instruct-GPTQ/resolve/main/gptq_model-4bit--1g.safetensors"
      ],
      "metadata": {
        "id": "I2G5JBkiE50B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4v4W-cEbE52w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQr_AC8sxBsp"
      },
      "outputs": [],
      "source": [
        "# Installation:\n",
        "!cd falcontune && pip install -r requirements.txt\n",
        "!cd falcontune && python setup.py install\n",
        "# !cd falcontune && python setup_cuda.py install  # if cuda, default is triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jYiffLuzCrq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart:\n",
        "import os; os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "7U56qd5G3frg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yBT2u0093lPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIHiDWRqzC-3"
      },
      "source": [
        "# GENERATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OrSjY3Mxt0x"
      },
      "outputs": [],
      "source": [
        "!falcontune generate \\\n",
        "    --interactive \\\n",
        "    --model falcon-40b-instruct-4bit \\\n",
        "    --weights gptq_model-4bit--1g.safetensors \\\n",
        "    --max_new_tokens 50 \\\n",
        "    --use_cache \\\n",
        "    --do_sample \\\n",
        "    --prompt \"How to prepare pasta?\" \\\n",
        "    --backend triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3_fPFI5xN6g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u78_DUqdzGrW"
      },
      "source": [
        "# FINETUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa0AzwyozGPX"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/gururise/AlpacaDataCleaned/raw/main/alpaca_data_cleaned.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmK1Xn-TzIqG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbdELbxDzIu7"
      },
      "outputs": [],
      "source": [
        "# Disable wandb:\n",
        "import os; os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRMdaD_dzIzE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMiUKv07zGSm"
      },
      "outputs": [],
      "source": [
        "!falcontune finetune \\\n",
        "    --model=falcon-40b-instruct-4bit \\\n",
        "    --weights=./gptq_model-4bit--1g.safetensors \\\n",
        "    --dataset=./alpaca_data_cleaned.json \\\n",
        "    --data_type=alpaca \\\n",
        "    --lora_out_dir=./falcon-40b-instruct-4bit-alpaca/ \\\n",
        "    --mbatch_size=1 \\\n",
        "    --batch_size=2 \\\n",
        "    --epochs=3 \\\n",
        "    --lr=3e-4 \\\n",
        "    --cutoff_len=256 \\\n",
        "    --lora_r=8 \\\n",
        "    --lora_alpha=16 \\\n",
        "    --lora_dropout=0.05 \\\n",
        "    --warmup_steps=5 \\\n",
        "    --save_steps=50 \\\n",
        "    --save_total_limit=3 \\\n",
        "    --logging_steps=5 \\\n",
        "    --target_modules='[\"query_key_value\"]' \\\n",
        "    --backend=triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMDvfC2nzO_1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aKvXziTziXY"
      },
      "source": [
        "# LOAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L_qtyiFzgv2"
      },
      "outputs": [],
      "source": [
        "!falcontune generate \\\n",
        "    --interactive \\\n",
        "    --model falcon-40b-instruct-4bit \\\n",
        "    --weights ./gptq_model-4bit--1g.safetensors \\\n",
        "    --lora_apply_dir falcon-40b-instruct-4bit-alpaca/ \\\n",
        "    --max_new_tokens 50 \\\n",
        "    --use_cache \\\n",
        "    --do_sample \\\n",
        "    --instruction \"How to prepare pasta?\" \\\n",
        "    --backend triton"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OOwapqyqWdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "duFhqd15qOev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Fm-7DODqOiR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}